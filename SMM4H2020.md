---
layout: default
---

## SMM4H at COLING 2020 Shared Task: Automatic classification of tweets that mention a medication

#### 
In this blog I write about my thought process for working on SMM4H 2020 Shared Task. Before starting I will be defining the task and that datasets in depth.  <br>
The Shared Task in Social Media Mining for Health Applications 2020 is defined as: *This binary classification task involves distinguishing tweets that mention a medication or dietary supplement (annotated as “1”) from those that do not (annotated as “0”).*
The dataset given to the participants represents the natural, highly imbalanced distribution of the two classes among tweets posted by 112 women during pregnancy2, with only approximately 0.2% of the tweets mentioning a medication.<br> 
<br>
The dataset distribution is as follows:<br>
Training data: 69,272 (181 “positive” tweets; 69,091 “negative” tweets)<br>
Test data: 29,687 tweets<br>
<br>
I chose to go ahead with this task by analysing the perfomance of the several pretrained encoders that we have in NLP as of now, with their extremely cute names, such as BERT, BioBERT, ClinicalBERT, SciBERT, RoBERTa, Biomed-RoBERTa, ELECTRA and ERNIE 2.0. They all differed in so many aspects that I decided it would be fun to work with them for a particular task and understand myself. There are still lots of questions that I do have, and also this is not a comprehensive list in any manner. :)
<br>
First let's see the final performance of the models on our shared task dataset:<br>

| Models    | F1 score |
| ----------- | ----------- |
| Header      | Title       |
| Paragraph   | Text        |
| Header      | Title       |
| Paragraph   | Text        |
| Header      | Title       |
| Paragraph   | Text        |





